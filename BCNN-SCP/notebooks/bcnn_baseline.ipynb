{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Seaborn style for visualization\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class SpatialCovariance(ABC):\n",
    "    def __call__(self, w, h):\n",
    "        xs = torch.linspace(0, 1, w)\n",
    "        ys = torch.linspace(0, 1, h)\n",
    "        points = [torch.tensor([x, y], dtype=torch.float) for x in xs for y in ys]\n",
    "        covar = torch.zeros(len(points), len(points))\n",
    "        for i in range(len(points)):\n",
    "            for j in range(i, len(points)):\n",
    "                x = points[i]\n",
    "                y = points[j]\n",
    "                covar[i, j] = self.kernel(x, y)\n",
    "                covar[j, i] = covar[i, j]\n",
    "        return covar\n",
    "\n",
    "    @abstractmethod\n",
    "    def kernel(self, x, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class RBFCovariance(SpatialCovariance):\n",
    "    def __init__(self, a, l):\n",
    "        self.a = a\n",
    "        self.l = l\n",
    "\n",
    "    def kernel(self, x, y):\n",
    "        diff = torch.norm(x - y)\n",
    "        return self.a * torch.exp(-(diff**2) / (2 * self.l**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and dataloader setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to mean=0.5 and std=0.5\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "dataset = datasets.MNIST(root='../data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='../data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into train and validation subsets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize a batch of images\n",
    "def visualize_images(dataloader, title=\"Images\"):\n",
    "    # Get a batch of images\n",
    "    images, labels = next(iter(dataloader))\n",
    "\n",
    "    # Denormalize images for visualization\n",
    "    images = images * 0.5 + 0.5  # Reverse normalization to [0, 1]\n",
    "\n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img, label, ax in zip(images[:8], labels[:8], axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')  # Display the single-channel image\n",
    "        ax.set_title(f\"Label: {label.item()}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize train, validation, and test batches\n",
    "visualize_images(train_loader, title=\"Visualise images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline B-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_DIV(mu_p, sig_p, mu_q, sig_q):\n",
    "    kl = 0\n",
    "    kernel_size = sig_q.shape[1]\n",
    "    blocks = sig_q.shape[0]\n",
    "    n = sig_q.shape[1]\n",
    "    sig_p_inv = torch.linalg.pinv(sig_p)\n",
    "    term_1_2 = torch.logdet(sig_p)\n",
    "    for i in range(blocks):\n",
    "        term_1_1 = torch.logdet(sig_q[i,:,:])\n",
    "        term_1 =  term_1_1 - term_1_2\n",
    "        term_3 = torch.trace(sig_p_inv @ sig_q[i,:,:])\n",
    "        mu_diff = (mu_q[kernel_size*i:kernel_size*(i+1)] - mu_p[kernel_size*i:kernel_size*(i+1)])\n",
    "        loss = (term_1 + n - term_3 - (mu_diff).T @ sig_p_inv @ (mu_diff))\n",
    "        # print(\"term11\", term_1_1)\n",
    "        # print(\"term12\", term_1_2)\n",
    "        # print(\"term3\", term_3)\n",
    "        # print(\"sig_p_inv\", sig_p_inv)\n",
    "        kl += loss\n",
    "\n",
    "    return -0.5*kl\n",
    "\n",
    "\n",
    "class RBF(gpytorch.kernels.RBFKernel):\n",
    "    def __init__(self, a, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.outputscale = a\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # covar = super().forward(x1, x2, **params)\n",
    "        covar = torch.eye(x1.shape[0])\n",
    "        return covar * self.outputscale\n",
    "\n",
    "class BBBConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, dilation=1, priors=None, num_samples=1):\n",
    "\n",
    "        super(BBBConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_shape = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.kernel_size = self.kernel_shape[0] * self.kernel_shape[1]\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = 1\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        prior_mu = torch.zeros(self.kernel_size*in_channels*out_channels,)\n",
    "        rbf_kernel = RBFCovariance(1, 1)\n",
    "        prior_covariance_matrix = rbf_kernel(self.kernel_shape[0], self.kernel_shape[1])\n",
    "\n",
    "        grid_size = self.kernel_shape[0]\n",
    "        x = torch.linspace(0, 1, grid_size)\n",
    "        y = torch.linspace(0, 1, grid_size)\n",
    "        xx, yy = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "        self.points = torch.stack([xx.ravel(), yy.ravel()], dim=-1)\n",
    "        self.counter = 0\n",
    "\n",
    "        if priors is None:\n",
    "            priors = {\n",
    "                'prior_mu': prior_mu,\n",
    "                'prior_cov': prior_covariance_matrix\n",
    "            }\n",
    "\n",
    "        # prior mean and convariance\n",
    "\n",
    "        self.prior_mu = priors['prior_mu']\n",
    "        self.prior_cov = priors['prior_cov']\n",
    "\n",
    "        # kernel for weight paramters (W_mu and W_sigma)\n",
    "        # a and l are learnable here\n",
    "\n",
    "        self.a = nn.Parameter(1+torch.rand(in_channels*out_channels))\n",
    "        self.l = nn.Parameter(1+torch.rand(in_channels*out_channels))\n",
    "\n",
    "        self.W_mu = nn.Parameter(torch.rand(in_channels*out_channels*self.kernel_size))\n",
    "        self.sampled_weights = torch.rand((self.num_samples,) + self.W_mu.shape)\n",
    "\n",
    "    def forward(self, input, sample=True):\n",
    "        # (B,S,C,H,W)\n",
    "        if self.training or sample:\n",
    "            # W_mu, a and l are learnable parameters\n",
    "            self.sample_weights()\n",
    "\n",
    "            # now we have sampled \"num_samples\" at once\n",
    "            # we iterate through the S dimension and run each set of weights for each sample\n",
    "            # it is guarenteed that self.num_samples matches with S (except for first layer, where input will have S = 1)\n",
    "            S = input.shape[1]\n",
    "            outputs = []\n",
    "            for i in range(self.num_samples):\n",
    "                weight = self.sampled_weights[i,:].view(self.out_channels, self.in_channels, self.kernel_shape[0], self.kernel_shape[1])\n",
    "\n",
    "                input_index = 0 if S == 1 else i\n",
    "                outputs.append(F.conv2d(input[:,input_index,:,:,:], weight, None, self.stride, self.padding, self.dilation, self.groups))\n",
    "            return torch.stack(outputs, dim=1)\n",
    "        else:\n",
    "            weight = self.W_mu.view(self.out_channels, self.in_channels, self.kernel_shape[0], self.kernel_shape[1])\n",
    "            return F.conv2d(input[:,0,:,:,:], weight, None, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def kl_loss(self):\n",
    "        return KL_DIV(self.prior_mu, self.prior_cov, self.W_mu, self.W_cov)\n",
    "\n",
    "    def sample_weights(self):\n",
    "        blocks = []\n",
    "        for i in range(self.in_channels*self.out_channels):\n",
    "            # different a and l for different filter (x,y)\n",
    "            rbf_kernel = RBFCovariance(self.a[i], self.l[i])\n",
    "\n",
    "            filterwise_covariance_matrix = rbf_kernel(self.kernel_shape[0], self.kernel_shape[1])\n",
    "            jitter = 1e-6 * torch.eye(filterwise_covariance_matrix.size(0))\n",
    "            filterwise_covariance_matrix += jitter\n",
    "\n",
    "            # samples \"num_samples\" weights at once\n",
    "            mvn = torch.distributions.MultivariateNormal(self.W_mu[self.kernel_size*i : self.kernel_size*i+self.kernel_size], filterwise_covariance_matrix)\n",
    "            self.sampled_weights[:, self.kernel_size*i : self.kernel_size*i+self.kernel_size] = mvn.sample((self.num_samples,))\n",
    "\n",
    "            self.counter+=1\n",
    "\n",
    "            blocks.append(filterwise_covariance_matrix)\n",
    "\n",
    "        self.W_cov = torch.stack(blocks) # concats only the blocks of the block diagonal covariance matrix\n",
    "\n",
    "class BayesianCNN(nn.Module):\n",
    "    def __init__(self, num_samples=1):\n",
    "        super(BayesianCNN, self).__init__()\n",
    "        self.conv1 = BBBConv2d(1, 32, kernel_size=3, stride=1, padding=1, num_samples=num_samples)\n",
    "        self.conv2 = BBBConv2d(32, 64, kernel_size=3, stride=1, padding=1, num_samples=num_samples)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        x = x_in.unsqueeze(1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        y=[]\n",
    "        for i in range(self.num_samples):\n",
    "            y.append(self.pool(x[:,i,:,:,:]))\n",
    "        y = torch.stack(y, dim=1)\n",
    "        y = y.view(y.size(0), y.size(1), -1)  # Flatten\n",
    "        y = torch.relu(self.fc1(y))\n",
    "        y = self.fc2(y)\n",
    "        y = F.log_softmax(y, dim=2)\n",
    "\n",
    "        kl = 0.0\n",
    "        for module in self.children():\n",
    "            if hasattr(module, 'kl_loss'):\n",
    "                module_kl_loss = module.kl_loss()\n",
    "                kl = kl + module_kl_loss\n",
    "\n",
    "        return y, kl\n",
    "\n",
    "class NonBayesianCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NonBayesianCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 32, 7, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=BBBConv2d(1,32,3,num_samples=100)\n",
    "model(torch.rand(64, 1, 1, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianCNN(num_samples=100)\n",
    "out = model(torch.rand(64, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 100, 10]), tensor(271874.1250, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape, out[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        # with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        #     tepoch.set_description(\"Evaluating\")\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            if len(outputs) == 2: outputs = outputs[0]\n",
    "\n",
    "            # Compute predictions and update accuracy metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Display current accuracy in the progress bar\n",
    "            accuracy = 100 * correct / total\n",
    "    accuracy = 100 * correct / total  # Overall accuracy\n",
    "    return accuracy\n",
    "\n",
    "def train_validate_and_evaluate(model, optimizer, device, epochs, train_loader, test_loader, val_loader, criterion=None, use_kl=True):\n",
    "    # Total number of batches across all epochs\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Single progress bar for all epochs\n",
    "    with tqdm(total=total_steps, unit=\"batch\") as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_combined_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # # One-hot encode labels\n",
    "                # one_hot_labels = F.one_hot(labels, num_classes=10).float()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                if len(outputs) == 2:\n",
    "                    logits, kl_loss = outputs\n",
    "                else:\n",
    "                    logits = outputs\n",
    "\n",
    "                # # Apply softmax to logits\n",
    "                # softmax_outputs = F.softmax(logits, dim=1)\n",
    "\n",
    "                # Average cross entropy loss across all samples\n",
    "                if len(logits.shape) == 3:\n",
    "                    logits = logits.permute(0, 2, 1) # (batch_size, num_samples, num_classes) -> (batch_size, num_classes, num_samples)\n",
    "                    labels = labels.unsqueeze(-1) # (batch_size, ) -> (batch_size, 1)\n",
    "                    labels = labels.expand(-1, logits.shape[-1]) # (batch_size, 1) -> (batch_size, num_samples)\n",
    "\n",
    "                cross_entropy_loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "                # Cross-entropy loss with one-hot labels\n",
    "                combined_loss = 0.0\n",
    "                if criterion: combined_loss += cross_entropy_loss\n",
    "                if use_kl: combined_loss += kl_loss\n",
    "\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                combined_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update metrics\n",
    "                total_combined_loss += combined_loss.item()\n",
    "\n",
    "                # Update the progress bar dynamically\n",
    "                pbar.set_description(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "                pbar.set_postfix(combined_loss=combined_loss.item())\n",
    "                pbar.update(1)\n",
    "\n",
    "            avg_combined_loss = total_combined_loss / len(train_loader)\n",
    "            losses.append(avg_combined_loss)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Avg Combined Loss: {avg_combined_loss:.4f}\")\n",
    "            val_acc = evaluate(model, val_loader, device)\n",
    "            val_accuracies.append(val_acc)\n",
    "            print(f\"Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    test_acc = evaluate(model, test_loader, device)\n",
    "    print(f\"Testing complete. Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    # Create a line plot\n",
    "    sns.lineplot(x=np.arange(epochs), y=losses)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs. Epoch\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Create a line plot\n",
    "    sns.lineplot(x=np.arange(epochs), y=val_accuracies)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Val Accuracy\")\n",
    "    plt.title(\"Val Accuracy vs. Epoch\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Non Bayesian CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c48fb7f891b467a8dfaac368da30eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_validate_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_kl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 69\u001b[0m, in \u001b[0;36mtrain_validate_and_evaluate\u001b[0;34m(model, optimizer, device, epochs, train_loader, test_loader, val_loader, criterion, use_kl)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m \u001b[43mcombined_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Update metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bml/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bml/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bml/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "model = NonBayesianCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_validate_and_evaluate(model, optimizer, device, epochs, train_loader, test_loader, val_loader, criterion=criterion, use_kl=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Bayesian CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcea7f7d49644478d98b1f971ac5d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_validate_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_kl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 69\u001b[0m, in \u001b[0;36mtrain_validate_and_evaluate\u001b[0;34m(model, optimizer, device, epochs, train_loader, test_loader, val_loader, criterion, use_kl)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m \u001b[43mcombined_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Update metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bml/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bml/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bml/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "model = BayesianCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_validate_and_evaluate(model, optimizer, device, epochs, train_loader, test_loader, val_loader, criterion=criterion, use_kl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
